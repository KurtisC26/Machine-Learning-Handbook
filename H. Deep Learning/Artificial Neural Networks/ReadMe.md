<h1> Artificial Neural Networks </h1>

The purpose of deep learning is to re-create the structure of the human brain within a machine. In order to do so, we want to try and create neurons...


<h2> Neurons </h2>
Neurons on there own do not have much power, the efficacy of neurons comes in numbers. When you have lots of neurons they work together to build something powerful

![image](https://user-images.githubusercontent.com/58488172/149626331-db4aedeb-9d5a-4bd6-96bc-37aeecae5a54.png)

Input varaibles need to be standardized / normalized

Output can be:
Continuous
binary
categorical --> Can have multiple output variables y1,y2,y3


For each of the inoput values, weights get attributed. They are crucial, and are the key elements that get modified in the process
![image](https://user-images.githubusercontent.com/58488172/149626417-d095e4c0-0203-4f84-b886-408297d9db02.png)


Within the neuron, we make sure the weights add up to 1 and then it will apply the activation function 

<h2> Activation Functions </h2>

There are four types of activation functions <br>
1) Threshold function<br>
![image](https://user-images.githubusercontent.com/58488172/149629078-ff306d8c-31dc-4c68-ad00-69b0f4588dda.png)


2) Sigmoid function<br>
![image](https://user-images.githubusercontent.com/58488172/149629093-e2a4f849-a5b4-4d3c-8136-f250d49157eb.png)

3) Rectifier Function <br>
![image](https://user-images.githubusercontent.com/58488172/149629116-9e5d22a7-ffcd-4afc-86a7-3925422a373f.png)

4) Hyperbolic Tangent Function<br>
![image](https://user-images.githubusercontent.com/58488172/149629134-2622c921-66a0-440a-8491-88f0de66dff2.png)







<h2> How do Neural Networks learn </h2>


